{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Tsou\\Documents\\Supelec\\3eme_annee\\Computer_Vision\\Project\\CVPR-2018-WAD-Video-Segmentation-Challenge\\utils.py:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./Models/U-Net/unet-29/unet.ckpt\n"
     ]
    }
   ],
   "source": [
    "from models import UNet\n",
    "from utils import entropy_loss\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "x_train_path = './Dataset/sample_train_color/'\n",
    "t_train_path = './Dataset/sample_train_label/'\n",
    "x_train_name = os.listdir(x_train_path)\n",
    "t_train_name = os.listdir(t_train_path)\n",
    "x_train_name = [x_train_path+s for s in x_train_name]\n",
    "x_train_name = x_train_name[0:100]\n",
    "x_train_name.sort()\n",
    "t_train_name = [t_train_path+s for s in t_train_name]\n",
    "t_train_name = t_train_name[0:100]\n",
    "t_train_name.sort()\n",
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "LR         = 1e-5\n",
    "img_height = 90\n",
    "img_width  = 422\n",
    "down_scale = 8\n",
    "class_num  = 9\n",
    "data_size  = len(x_train_name)\n",
    "n_batches  = int(math.ceil(data_size/batch_size))\n",
    "\n",
    "\n",
    "# This cell is used to construct the pipeline of dataset\n",
    "def _parse_function(x_name, t_name, img_shape, down_scale):\n",
    "    x_string = tf.read_file(x_name)\n",
    "    x = tf.image.decode_jpeg(x_string, channels=3)\n",
    "    x = x[1560:2280, 7:-7]/1000\n",
    "    x = tf.image.resize_images(x, img_shape)\n",
    "    t_string = tf.read_file(t_name)\n",
    "    t = tf.image.decode_png(t_string, channels=1, dtype=tf.uint16)\n",
    "    t = t[1560:2280, 7:-7]\n",
    "    t = t[::down_scale, ::down_scale]\n",
    "    t = tf.cast(t/1000, tf.int32)\n",
    "    \n",
    "    shape = tf.shape(t)\n",
    "    t = tf.reshape(t, (shape[0]*shape[1],))\n",
    "    t = tf.one_hot(t, depth=41)\n",
    "    t = tf.concat([t[:, 0:1], t[:, 33:]], axis=1)\n",
    "    t = tf.reshape(t, (shape[0], shape[1], 9))\n",
    "    \n",
    "    return x, t\n",
    "\n",
    "x_filenames = tf.constant(x_train_name)\n",
    "t_filenames = tf.constant(t_train_name)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_filenames, t_filenames))\n",
    "dataset = dataset.map(lambda x, y: _parse_function(x, y, (img_height, img_width), down_scale))\n",
    "dataset = dataset.batch(batch_size).repeat(1)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "x_batch, t_batch = next_batch # get the tf variable of input and target images\n",
    "\n",
    "\n",
    "unet = UNet(x=x_batch, t=t_batch,\n",
    "            LR=1e-8, input_shape=[None, img_height, img_width, 3], \n",
    "            output_shape=[None, img_height, img_width, class_num], )\n",
    "unet.optimize(entropy_loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(iterator.initializer)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, './Models/U-Net/unet-29/unet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [03:35<00:00, 51.51s/it]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "for _ in tqdm.tqdm(range(n_batches)):\n",
    "    y = sess.run(unet.y)\n",
    "    y_train += [y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 90, 422, 9]\n"
     ]
    }
   ],
   "source": [
    "print(unet.output_shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow-1-12]",
   "language": "python",
   "name": "Python [tensorflow-1-12]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
