{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np                                \n",
    "from skimage import measure                       \n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def create_sub_masks(mask_image):\n",
    "    width, height = mask_image.size\n",
    "\n",
    "    # Initialize a dictionary of sub-masks indexed by RGB colors\n",
    "    sub_masks = {}\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # Get the RGB values of the pixel\n",
    "            #print(type(mask_image))\n",
    "            #pdb.set_trace()\n",
    "            pixel = mask_image.getpixel((x,y))[:3]\n",
    "\n",
    "            # If the pixel is not black...\n",
    "            if pixel != (0, 0, 0):\n",
    "                # Check to see if we've created a sub-mask...\n",
    "                pixel_str = str(pixel)\n",
    "                sub_mask = sub_masks.get(pixel_str)\n",
    "                if sub_mask is None:\n",
    "                   # Create a sub-mask (one bit per pixel) and add to the dictionary\n",
    "                    # Note: we add 1 pixel of padding in each direction\n",
    "                    # because the contours module doesn't handle cases\n",
    "                    # where pixels bleed to the edge of the image\n",
    "                    sub_masks[pixel_str] = Image.new('1', (width+2, height+2))\n",
    "\n",
    "                # Set the pixel value to 1 (default is 0), accounting for padding\n",
    "                sub_masks[pixel_str].putpixel((x+1, y+1), 1)\n",
    "\n",
    "    return sub_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd):\n",
    "    # Find contours (boundary lines) around each sub-mask\n",
    "    # Note: there could be multiple contours if the object\n",
    "    # is partially occluded. (E.g. an elephant behind a tree)\n",
    "    contours = measure.find_contours(sub_mask, 0.5, positive_orientation='low')\n",
    "\n",
    "    segmentations = []\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        for i in range(len(contour)):\n",
    "            row, col = contour[i]\n",
    "            contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        poly = Polygon(contour)\n",
    "        poly = poly.simplify(1.0, preserve_topology=False)\n",
    "        polygons.append(poly)\n",
    "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "        segmentations.append(segmentation)\n",
    "\n",
    "    # Combine the polygons to calculate the bounding box and area\n",
    "    multi_poly = MultiPolygon(polygons)\n",
    "    x, y, max_x, max_y = multi_poly.bounds\n",
    "    width = max_x - x\n",
    "    height = max_y - y\n",
    "    bbox = (x, y, width, height)\n",
    "    area = multi_poly.area\n",
    "\n",
    "    annotation = {\n",
    "        'segmentation': segmentations,\n",
    "        'iscrowd': is_crowd,\n",
    "        'image_id': image_id,\n",
    "        'category_id': category_id,\n",
    "        'id': annotation_id,\n",
    "        'bbox': bbox,\n",
    "        'area': area\n",
    "    }\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Annotations for Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-41-eb3ff4371724>(12)create_sub_masks()\n",
      "-> pixel = mask_image.getpixel((x,y))[:3]\n",
      "(Pdb) x\n",
      "0\n",
      "(Pdb) y\n",
      "0\n",
      "(Pdb) mask_image\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=P size=512x512 at 0x7FB1F44E06D8>\n",
      "(Pdb) mask_image.getpixel(x,y)[:3]\n",
      "*** TypeError: getpixel() takes 2 positional arguments but 3 were given\n",
      "(Pdb) pixel = mask_image.getpixel((x,y))[:3]\n",
      "*** TypeError: 'int' object is not subscriptable\n",
      "(Pdb) tmp = np.array(mask_image)\n",
      "(Pdb) tmp\\\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)\n",
      "(Pdb) tmp\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)\n",
      "(Pdb) tmp.shape\n",
      "(512, 512)\n",
      "(Pdb) x\n",
      "0\n",
      "(Pdb) print(type(x))\n",
      "<class 'int'>\n",
      "(Pdb) print(y)\n",
      "0\n",
      "(Pdb) print(type(y))\n",
      "<class 'int'>\n",
      "(Pdb) pixel = mask_image.getpixel((x,y))\n",
      "(Pdb) pixel\n",
      "0\n",
      "(Pdb) tmp.shape\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "plant_book_mask_image = Image.open('/home/ayush/Instance_Segmentation/all/Mask_RCNN/Practice_Dataset/train/plant_book_mask.png')\n",
    "bottle_book_mask_image = Image.open('/home/ayush/Instance_Segmentation/all/Mask_RCNN/Practice_Dataset/val/bottle_book_mask.png')\n",
    "\n",
    "mask_images = [plant_book_mask_image, bottle_book_mask_image]\n",
    "\n",
    "# Define which colors match which categories in the images\n",
    "houseplant_id, book_id, bottle_id, lamp_id = [1, 2, 3, 4]\n",
    "category_ids = {\n",
    "    1: {\n",
    "        '(0, 255, 0)': houseplant_id,\n",
    "        '(0, 0, 255)': book_id,\n",
    "    },\n",
    "    2: {\n",
    "        '(255, 255, 0)': bottle_id,\n",
    "        '(255, 0, 128)': book_id,\n",
    "        '(255, 100, 0)': lamp_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "is_crowd = 0\n",
    "\n",
    "# These ids will be automatically increased as we go\n",
    "annotation_id = 1\n",
    "image_id = 1\n",
    "\n",
    "# Create the annotations\n",
    "annotations = []\n",
    "for mask_image in mask_images:\n",
    "    sub_masks = create_sub_masks(mask_image)\n",
    "    for color, sub_mask in sub_masks.items():\n",
    "        #print('Image_ID', image_id)\n",
    "        #print('Color',color)\n",
    "        category_id = category_ids[image_id][color]\n",
    "        annotation = create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd)\n",
    "        annotations.append(annotation)\n",
    "        annotation_id += 1\n",
    "    image_id += 1\n",
    "\n",
    "print(json.dumps(annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Annotations for Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
