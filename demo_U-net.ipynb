{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import UNet\n",
    "from utils import entropy_loss\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "x_train_path = './Dataset/sample_train_color/'\n",
    "t_train_path = './Dataset/sample_train_label/'\n",
    "x_train_name = os.listdir(x_train_path)\n",
    "t_train_name = os.listdir(t_train_path)\n",
    "x_train_name = [x_train_path+s for s in x_train_name]\n",
    "x_train_name.sort()\n",
    "x_train_name = x_train_name[0:10]\n",
    "t_train_name = [t_train_path+s for s in t_train_name]\n",
    "t_train_name.sort()\n",
    "t_train_name = t_train_name[0:10]\n",
    "\n",
    "# parameters\n",
    "batch_size = 1 # 32\n",
    "epoch      = 1 # 30\n",
    "LR         = 1e-4\n",
    "img_height = 90\n",
    "img_width  = 422\n",
    "down_scale = 8\n",
    "class_num  = 9\n",
    "data_size  = len(x_train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell is used to construct the pipeline of dataset\n",
    "def _parse_function(x_name, t_name, img_shape, down_scale):\n",
    "    x_string = tf.read_file(x_name)\n",
    "    x = tf.image.decode_jpeg(x_string, channels=3)\n",
    "    x = x[1560:2280, 7:-7]/1000\n",
    "    x = tf.image.resize_images(x, img_shape)\n",
    "    t_string = tf.read_file(t_name)\n",
    "    t = tf.image.decode_image(t_string, channels=1, dtype=tf.uint16)\n",
    "    t = t[1560:2280, 7:-7]\n",
    "    t = t[::down_scale, ::down_scale]\n",
    "    t = tf.cast(t/1000, tf.int32)\n",
    "    \n",
    "    shape = tf.shape(t)\n",
    "    t = tf.reshape(t, (shape[0]*shape[1],))\n",
    "    t = tf.one_hot(t, depth=41)\n",
    "    t = tf.concat([t[:, 0:1], t[:, 33:]], axis=1)\n",
    "    t = tf.reshape(t, (shape[0], shape[1], 9))\n",
    "    \n",
    "    return x, t#tf.cast(t, tf.float32)\n",
    "\n",
    "x_filenames = tf.constant(x_train_name)\n",
    "t_filenames = tf.constant(t_train_name)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_filenames, t_filenames))\n",
    "dataset = dataset.map(lambda x, y: _parse_function(x, y, (img_height, img_width), down_scale))\n",
    "dataset = dataset.shuffle(buffer_size=32).batch(batch_size).repeat(epoch)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "x_batch, t_batch = next_batch # get the tf variable of input and target images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Tsou\\Documents\\Supelec\\3eme_annee\\Computer_Vision\\Project\\CVPR-2018-WAD-Video-Segmentation-Challenge\\utils.py:77: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unet = UNet(x=x_batch, t=t_batch,\n",
    "            LR=1e-8, input_shape=[None, img_height, img_width, 3], \n",
    "            output_shape=[None, img_height, img_width, class_num], )\n",
    "unet.optimize(entropy_loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(iterator.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Loss: 2.31612697 | Time:   28.5\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(max_to_keep=epoch)\n",
    "if not os.path.isdir('./Models'):\n",
    "    os.mkdir('./Models')\n",
    "    os.mkdir('./Models/U-Net/')\n",
    "elif not os.path.isdir('./Models/U-Net/'):\n",
    "    os.mkdir('./Models/U-Net/')\n",
    "    \n",
    "for ep in range(epoch):\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    start = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            _, loss = sess.run([unet.training, unet.loss])\n",
    "            \n",
    "            total_loss += loss\n",
    "            counter += 1\n",
    "            \n",
    "        except:\n",
    "            break\n",
    "    end = time.time()\n",
    "    message = 'Epoch: {:>2} | Loss: {:>10.8f} | Time: {:>6.1f}'\n",
    "    print(message.format(ep, total_loss/counter, end-start))\n",
    "    \n",
    "    if not os.path.isdir('./Models/U-Net/unet-'+str(ep)):\n",
    "        os.mkdir('./Models/U-Net/unet-'+str(ep))\n",
    "    save_path = saver.save(sess, './Models/U-Net/unet-'+str(ep)+'/unet.ckpt')\n",
    "    \n",
    "    if ep==0 and os.path.isfile('./log'):\n",
    "        os.remove('./log')\n",
    "    with open('./log', 'a') as file_write:\n",
    "        file_write.write(message.format(ep, total_loss/counter, end-start))\n",
    "        file_write.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow-1-12]",
   "language": "python",
   "name": "Python [tensorflow-1-12]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
